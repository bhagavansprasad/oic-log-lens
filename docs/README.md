# OIC-LogLens ğŸ”

**AI-Powered Error Resolution Engine for Oracle Integration Cloud**

Transform OIC troubleshooting from reactive debugging to AI-driven resolution intelligence. OIC-LogLens automatically detects duplicate errors, suggests solutions from past incidents, and eliminates repeated manual investigations.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.32+-red.svg)](https://streamlit.io/)

---

## ğŸ“‹ Table of Contents

- [Problem Statement](#problem-statement)
- [Solution](#solution)
- [Architecture](#architecture)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [Quick Start](#quick-start)
- [Installation](#installation)
- [Usage](#usage)
- [API Documentation](#api-documentation)
- [Web UI](#web-ui)
- [Testing](#testing)
- [Project Structure](#project-structure)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Problem Statement

In complex Oracle Integration Cloud (OIC) environments, teams face recurring challenges:

### Repeated Errors Across Integrations
- Similar payload failures
- XSLT transformation errors
- API invocation issues (400/500)
- ESS job failures
- FBDI load errors
- Connectivity/authentication issues

### Manual Investigation Process
Teams often:
- âœ— Manually review logs
- âœ— Search old Jira tickets
- âœ— Ask senior developers
- âœ— Reinvestigate already-solved issues

### Impact
- â° Wasted effort on duplicate investigations
- ğŸŒ Slow resolution times
- ğŸ‘¤ Dependency on SMEs
- â¬‡ï¸ Increased downtime and MTTR



### Log Data Characteristics

**Important Constraints:**
- Each log file represents a **single workflow execution**
- Each error log file results in **one record** in the database
- Log files are always provided in **valid JSON format**
- Each log file contains a **list of JSON objects**
- The structure of JSON objects is **not uniform** and may vary between log files (different keys and nesting)

**Implication:**  
Because the log structure is not fixed, the system must **normalize** the incoming log into a consistent schema before:
- Storing it in the database
- Generating embeddings
- Performing semantic search

---

## âœ… Solution

OIC-LogLens transforms troubleshooting with AI-powered semantic search:

### How It Works

```
New Error Occurs â†’ Submit to OIC-LogLens â†’ Get Similar Past Issues â†’ Resolve in Minutes
```

**Instead of:**
- 30 min: Manual log review
- 20 min: Searching Jira tickets
- 45 min: Waiting for SME response
- **Total: ~2 hours MTTR**

**You Get:**
- 1 min: Submit log
- Instant: Get similar issues with Jira IDs
- 5 min: Apply known solution
- **Total: ~6 minutes MTTR** âš¡

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â”‚ (OIC Admin) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI REST API                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  /ingest/file  /ingest/url      â”‚   â”‚
â”‚  â”‚  /ingest/raw   /ingest/database â”‚   â”‚
â”‚  â”‚  /search                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚
       â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gemini AI   â”‚      â”‚ Oracle 26ai  â”‚
â”‚              â”‚      â”‚ Vector DB    â”‚
â”‚ â€¢ 2.0 Flash  â”‚      â”‚              â”‚
â”‚ â€¢ Embeddings â”‚      â”‚ OLL_LOGS     â”‚
â”‚   (3072 dim) â”‚      â”‚ â€¢ HNSW Index â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

**Use Case 1: Ingestion (Write Path)**
```
Raw Log â†’ Normalize (LLM) â†’ Generate Embedding â†’ Store in Vector DB
```

**Use Case 2: Search (Read Path)**
```
New Log â†’ Normalize (LLM) â†’ Generate Embedding â†’ Vector Similarity Search â†’ Return Top-5 Matches
```

### RAG Architecture

OIC-LogLens implements **Retrieval Augmented Generation (RAG)**:
- **Retrieve:** Vector similarity search finds Top-5 similar logs
- **Augment:** Retrieved context (Jira IDs, error summaries)
- **Generate:** Present ranked results to user



### Storage Model

For each processed log, the system stores in **Oracle 26ai VectorDB**:

1. **Original Log** â€” Raw log file in native JSON format for traceability and reprocessing
2. **Normalized Log** â€” Structured and consistent representation generated after normalization
3. **Vector Embeddings** â€” Embeddings from selected critical fields of the normalized log
4. **Metadata** â€” LOG_HASH (SHA256), JIRA_ID, flow_code, error_code, timestamps

**Purpose:** This enables efficient semantic matching while preserving original data for audit and reprocessing.

---

## âœ¨ Features

### ğŸ” Duplicate Detection
- **LOG_HASH check before LLM calls** â€” saves 10-15 seconds per duplicate
- Instant 409 Conflict response for duplicates
- SHA256 hash ensures uniqueness

### ğŸ“¥ Multiple Ingestion Methods
1. **File Upload** â€” Browse and upload JSON files
2. **URL** â€” Fetch from HTTP/HTTPS (GCS, S3, GitHub)
3. **Raw Text** â€” Copy-paste JSON directly
4. **Database Query** â€” Load from Oracle/other DB (supports batch)

### ğŸ” Semantic Search with LLM Re-ranking
- **Vector similarity** using cosine distance (initial Top-5)
- **LLM re-ranking** â€” Gemini analyzes context and classifies results
- **4 classification types:**
  - ğŸŸ¢ EXACT_DUPLICATE (90-100%) â€” Same issue, same fix
  - ğŸŸ¡ SIMILAR_ROOT_CAUSE (70-89%) â€” Same underlying problem
  - ğŸŸ  RELATED (50-69%) â€” May provide useful context
  - âšª NOT_RELATED (0-49%) â€” Different issue
- **Confidence scores (0-100)** â€” Trust the ranking
- **Reasoning provided** â€” Understand why it's classified
- **Jira ID linking** â€” instant access to past resolutions
- **Root cause comparison** â€” Full normalized log context

### ğŸ¤– AI-Powered Intelligence
- **LLM-based normalization** (Gemini 2.0 Flash)
  - Handles structural variability across OIC log formats
  - Extracts: flow info, error details, tracking variables, user data
- **LLM re-ranking with structured output**
  - Classifies duplicates with 100% confidence when exact match
  - Provides reasoning for each classification
  - Uses full normalized log context (including root cause)

### ğŸ“Š Batch Processing
- Ingest multiple logs in one database query
- Summary with success/duplicate/failed counts
- Individual result tracking

### ğŸ¨ Beautiful Web UI
- **Streamlit interface** â€” no coding required
- File upload with preview
- Real-time API status
- Color-coded results
- Expandable search results

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|---|---|---|
| **Backend** | FastAPI | REST API server |
| **UI** | Streamlit | Web interface |
| **LLM** | Gemini 2.0 Flash | Log normalization + re-ranking |
| **Structured Output** | JSON Schema | Type-safe LLM responses |
| **Embeddings** | gemini-embedding-001 | 3072-dim vectors |
| **Vector DB** | Oracle 26ai | Vector storage + search |
| **Vector Index** | HNSW | 95% accuracy, cosine distance |
| **Language** | Python 3.8+ | Core implementation |
| **API Docs** | Swagger/OpenAPI | Auto-generated docs |

---

## ğŸš€ Quick Start

### Prerequisites

```bash
# Python 3.8+
python --version

# Oracle 26ai Database
docker ps | grep oracle

# Gemini API Key
export GOOGLE_API_KEY="your-api-key"
```

### Install

```bash
# Clone repository
git clone https://github.com/bhagavansprasad/oic-log-lens.git
cd oic-log-lens/src

# Install dependencies
pip install fastapi uvicorn oracledb google-generativeai streamlit requests --break-system-packages
```

### Run

```bash
# Terminal 1: Start API
python main.py
# API runs at http://localhost:8000

# Terminal 2: Start UI (optional)
streamlit run app.py
# UI runs at http://localhost:8501
```

### Test

```bash
# Health check
curl http://localhost:8000/health

# Ingest a log
curl -X POST http://localhost:8000/ingest/file \
  -H "Content-Type: application/json" \
  -d '{"file_path": "flow-logs/01_flow-log.json"}'

# Search for similar logs (using Python)
python tests/test_search_api.py
```

---

## ğŸ“¦ Installation

### 1. System Requirements

- **Python:** 3.8 or higher
- **Database:** Oracle 26ai (Docker recommended)
- **Memory:** 4GB RAM minimum
- **Storage:** 2GB for models and data

### 2. Database Setup

```bash
# Pull Oracle 26ai Docker image
docker pull container-registry.oracle.com/database/free:latest

# Run Oracle 26ai
docker run -d \
  --name oracle26ai_db \
  -p 1521:1521 \
  -e ORACLE_PWD=YourPassword123 \
  container-registry.oracle.com/database/free:latest

# Create schema
cd OIC-LogLens/src
docker cp oll_schema.sql oracle26ai_db:/tmp/
docker exec -it oracle26ai_db sqlplus EA_APP/YourPassword@FREEPDB1 @/tmp/oll_schema.sql
```



### Database Connection

```bash
# Connect to Oracle 26ai via Docker
docker exec -it oracle26ai_db_bhagavan sqlplus EA_APP/jnjnuh@FREEPDB1

# Useful commands
SHOW USER;
SELECT table_name FROM user_tables;
SELECT * FROM OLL_LOGS;
SELECT COUNT(*) FROM OLL_LOGS;
TRUNCATE TABLE OLL_LOGS;

# Copy SQL file to container
docker cp oic_kb_schema.sql oracle26ai_db_bhagavan:/tmp/oic_kb_schema.sql
docker exec -it oracle26ai_db_bhagavan sqlplus EA_APP/jnjnuh@FREEPDB1 @/tmp/oic_kb_schema.sql

docker cp kg_schema.sql oracle26ai_db_bhagavan:/tmp/kg_schema.sql
docker exec -it oracle26ai_db_bhagavan sqlplus EA_APP/jnjnuh@FREEPDB1 @/tmp/kg_schema.sql
```

### 3. Python Dependencies

```bash
pip install -r requirements.txt --break-system-packages
```

**requirements.txt:**
```
fastapi>=0.104.0
uvicorn>=0.24.0
oracledb>=1.4.0
google-generativeai>=0.3.0
pydantic>=2.5.0
requests>=2.31.0
streamlit>=1.32.0  # For UI only
```

### 4. Environment Configuration

```bash
# Set Gemini API key
export GOOGLE_API_KEY="your-gemini-api-key"

# Or create .env file
echo "GOOGLE_API_KEY=your-gemini-api-key" > .env
```

### 5. Verify Installation

```bash
# Check Python version
python --version

# Test imports
python -c "import fastapi, oracledb, google.generativeai; print('âœ… All dependencies installed')"

# Test database connection
python -c "import oracledb; conn = oracledb.connect('EA_APP/password@localhost/FREEPDB1'); print('âœ… Database connected')"
```

---

## ğŸ“– Usage

### API Server

```bash
# Start server
cd OIC-LogLens/src
python main.py

# Server starts at http://localhost:8000
# API docs at http://localhost:8000/docs
```

### Web UI

```bash
# Start UI (in separate terminal)
streamlit run app.py

# UI opens at http://localhost:8501
```

### Command Line

```bash
# Run all tests
cd tests
bash test_api_examples.sh

# Test specific endpoint
python test_search_api.py
```

---

## ğŸŒ API Documentation

### Endpoints

| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/health` | Health check |
| `POST` | `/ingest/file` | Ingest from file path |
| `POST` | `/ingest/url` | Ingest from URL |
| `POST` | `/ingest/raw` | Ingest from raw JSON |
| `POST` | `/ingest/database` | Ingest from DB query (batch) |
| `POST` | `/search` | Search for similar logs |

### Example: Ingest from File

**Request:**
```bash
curl -X POST http://localhost:8000/ingest/file \
  -H "Content-Type: application/json" \
  -d '{
    "file_path": "flow-logs/01_flow-log.json"
  }'
```

**Response:**
```json
{
  "log_id": "9f9da348-963c-41fe-8c61-3ec23dbb3c13",
  "jira_id": "https://promptlyai.atlassian.net/browse/OLL-4FF0674A",
  "status": "success",
  "message": "Log ingested successfully"
}
```

### Example: Search for Duplicates

**Request:**
```bash
curl -X POST http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{
    "log_content": "[{...log json...}]"
  }'
```

**Response:**
```json
{
  "status": "success",
  "message": "Found 5 similar logs",
  "matches": [
    {
      "jira_id": "https://promptlyai.atlassian.net/browse/OLL-4FF0674A",
      "similarity_score": 100.0,
      "flow_code": "RH_NAVAN_DAILY_INTEGR_SCHEDU",
      "trigger_type": "scheduled",
      "error_code": "Execution failed",
      "error_summary": "oracle.cloud.connector.api.CloudInvocationException"
    }
  ]
}
```

**Interactive API Docs:** Open browser â†’ `http://localhost:8000/docs`

---

## ğŸ¨ Web UI

### Features

- **ğŸ“¥ Ingest Page** â€” 4 tabs (Upload, URL, Raw, Database)
- **ğŸ” Search Page** â€” File upload + text input
- **ğŸ“Š Dashboard** â€” System overview
- **âœ… Real-time status** â€” API health indicator
- **ğŸ¯ One-click actions** â€” No command line needed

### Screenshots

Coming soon! (Add screenshots of your UI here)

### Usage

1. Start API server: `python main.py`
2. Start UI: `streamlit run app.py`
3. Open browser: `http://localhost:8501`
4. Upload a log or paste JSON
5. Get results instantly!

---

## ğŸ§ª Testing

See [TESTING.md](TESTING.md) for comprehensive testing guide.

### Quick Test

```bash
# Health check
curl http://localhost:8000/health

# Ingest all test logs
cd tests
bash test_api_examples.sh

# Search test
python test_search_api.py
```

### Test Data

8 sample OIC error logs in `flow-logs/`:
- CloudInvocationException (404)
- SQL table not found
- HTTP 503 service unavailable
- ERP SOAP fault
- Supplier creation error (400)
- Authentication failure (401)
- REST endpoint 406 error
- FTP file not found

---

## ğŸ“ Project Structure

```
OIC-LogLens/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ app.py                  # Streamlit UI
â”‚   â”œâ”€â”€ models.py               # Pydantic models
â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â”œâ”€â”€ prompts.py              # LLM prompts
â”‚   â”œâ”€â”€ normalizer.py           # Log normalization
â”‚   â”œâ”€â”€ embedder.py             # Embedding generation
â”‚   â”œâ”€â”€ ingestion_service.py    # Ingestion pipeline
â”‚   â”œâ”€â”€ search_service.py       # Search pipeline
â”‚   â”œâ”€â”€ db.py                   # Database operations
â”‚   â”œâ”€â”€ oll_schema.sql          # Database schema
â”‚   â”œâ”€â”€ flow-logs/              # Test log files
â”‚   â””â”€â”€ tests/                  # Test scripts
â”‚       â”œâ”€â”€ test_api_examples.sh
â”‚       â”œâ”€â”€ test_search_api.py
â”‚       â”œâ”€â”€ test_normalize.py
â”‚       â””â”€â”€ load_logs_to_db.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ NORMALIZATION.md        # Normalization docs
â”‚   â”œâ”€â”€ usecase1-ingestion.png  # Architecture diagram
â”‚   â””â”€â”€ usecase2-search.png     # Architecture diagram
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ TESTING.md                  # Testing guide
â”œâ”€â”€ UI-README.md                # UI guide
â””â”€â”€ requirements.txt            # Dependencies
```

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Google Gemini** â€” LLM and embedding models
- **Oracle** â€” Oracle 26ai Vector Database
- **FastAPI** â€” Modern API framework
- **Streamlit** â€” Beautiful UI framework

---

## ğŸ“ Contact

**Project Maintainer:** Bhagavan Prasad  
**GitHub:** [@bhagavansprasad](https://github.com/bhagavansprasad)  
**Repository:** [oic-log-lens](https://github.com/bhagavansprasad/oic-log-lens)


---

## ğŸ§  How LLM Re-ranking Works

### The Problem with Pure Vector Search

Vector similarity (cosine distance) is **mathematical**, not **semantic**:

```
Query: "404 Not Found error in RH_NAVAN flow"
Result 1: 68% similar - "Table not found in SQL query" âŒ
Result 2: 67% similar - "404 Not Found error in RH_NAVAN flow" âœ…
```

**Result 1 has higher similarity** (more overlapping words) but **Result 2 is the actual duplicate!**

### The Solution: LLM Re-ranking

After vector search returns Top-5, the LLM:

1. **Receives full context** â€” normalized logs with root causes
2. **Analyzes semantically** â€” understands error meaning, not just words
3. **Classifies** â€” EXACT_DUPLICATE vs SIMILAR vs RELATED vs NOT_RELATED
4. **Provides confidence** â€” 100% for exact matches, lower for uncertain
5. **Explains reasoning** â€” "Same flow, same error, same root cause"

### Result

```
Before: 5 results with % scores (user must investigate all)
After:  ğŸŸ¢ EXACT_DUPLICATE (100%) â† Use this Jira, don't create new!
        ğŸŸ¡ SIMILAR (75%) â† Check this solution first
        âšª NOT_RELATED (30%) â† Ignore
```

**From 10 minutes of investigation â†’ 1 minute decision**

---

## ğŸš€ What's Next?

- [ ] LLM re-ranking for smarter duplicate classification
- [ ] Docker deployment setup
- [ ] Performance optimization (caching, connection pooling)
- [ ] Monitoring and analytics dashboard
- [ ] Multi-tenancy support
- [ ] Scheduled log polling from OIC


---

## ğŸ“ TODO / Future Enhancements

- [x] **LLM re-ranking** â€” âœ… Implemented with structured output and 100% confidence
- [ ] **Docker deployment** â€” Production-ready containerization with .env config
- [ ] **Data masking** â€” Implement PII masking (email IDs, user IDs, credentials)
- [ ] **Sequence diagrams** â€” Add detailed RAG flow diagrams
- [ ] **Performance optimization** â€” Add caching, connection pooling
- [ ] **Monitoring dashboard** â€” Real-time stats, log history viewer
- [ ] **Table naming** â€” Consider renaming `OLL_LOGS` to more descriptive name


---

**Built with â¤ï¸ for the Oracle Integration Cloud community**
